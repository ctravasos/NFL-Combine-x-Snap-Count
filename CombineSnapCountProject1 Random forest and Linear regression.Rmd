---
title: "Combine x Snap Count"
author: "Alaina, Collin, Max, Stef"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Packages
```{r}
library(httr) 
library(rvest) 
library(jsonlite) 
library(tidyverse)
library(dplyr)
library(ggplot2)
library(dplyr)
library(rvest)

```

Load in snap counts via scrape
Not needed with second chunk can delete this whenever
```{r}
urlD23 <- "https://www.fantasypros.com/nfl/reports/snap-counts/defense.php?year=2023"
fpD23 <- read_html(urlD23)
table_fpD23 <- fpD23 %>% 
  html_node("table") %>% 
  html_table()
table_fpD23 <- table_fpD23 %>%
  mutate(across(everything(), ~ ifelse(. == "bye", "0", .))) %>% 
  mutate(across(-c(1:3), as.integer))

urlO23 <- "https://www.fantasypros.com/nfl/reports/snap-counts/?year=2023"
fpO23 <- read_html(urlO23)
table_fpO23 <- fpO23 %>% 
  html_node("table") %>% 
  html_table()
table_fpO23 <- table_fpO23 %>%
  mutate(across(everything(), ~ ifelse(. == "bye", "0", .))) %>% 
  mutate(across(-c(1:3), as.integer))

table_fpD23
  table_fpD23$Player_Team <- paste(table_fpD23$Player, table_fpD23$Team)
  
  table_fpD23 <- table_fpD23 %>%
    select(-Player, Team)
    
table_fpO23
  table_fpO23$Player_Team <- paste(table_fpO23$Player, table_fpO23$Team)
  
  table_fpO23 <- table_fpO23 %>%
    select(-Player, Team)

```

All Years available on Fantasy Pros
```{r}

#DEFENSE
# Function to scrape and process the table for a given year
process_table_D <- function(year) {
  url_D <- paste0("https://www.fantasypros.com/nfl/reports/snap-counts/defense.php?year=", year)
  table_D <- read_html(url_D) %>%
    html_node("table") %>%
    html_table()
  
  # Replace "bye" with "0" and convert columns to integers
  table_D <- table_D %>%
    mutate(across(everything(), ~ ifelse(. == "bye", "0", .))) %>%
    mutate(across(-c(1:3), as.integer))
  
  return(table_D)
}

# List to store tables
tables_list_D <- list()

# Loop through the years and process the tables
for (year in 2016:2023) {
  tables_list_D[[as.character(year)]] <- process_table_D(year)
}

# Combine all tables into one
fpD_snap_table <- bind_rows(tables_list_D, .id = "Year")

#OFFENSE
# Function to scrape and process the table for a given year
process_table_O <- function(year) {
  url_O <- paste0("https://www.fantasypros.com/nfl/reports/snap-counts/?year=", year)
  table_O <- read_html(url_O) %>%
    html_node("table") %>%
    html_table()
  
  # Replace "bye" with "0" and convert columns to integers
  table_O <- table_O %>%
    mutate(across(everything(), ~ ifelse(. == "bye", "0", .))) %>%
    mutate(across(-c(1:3), as.integer))
  
  return(table_O)
}

# List to store tables
tables_list_O <- list()

# Loop through the years and process the tables
for (year in 2016:2023) {
  tables_list_O[[as.character(year)]] <- process_table_O(year)
}

# Combine all tables into one
fpO_snap_table <- bind_rows(tables_list_O, .id = "Year")


# Combine O and D
fp_snap_table <- bind_rows(fpD_snap_table, fpO_snap_table)
```

pivot that ho
```{r}
library(tidyr)
library(dplyr)

# Ensure all columns are character type before pivoting
fpD_snap_table <- fpD_snap_table %>%
  mutate(across(everything(), as.character))

fpO_snap_table <- fpO_snap_table %>%
  mutate(across(everything(), as.character))

# Identify and resolve duplicates in the defense table
fpD_snap_table <- fpD_snap_table %>%
  group_by(Player, Pos, Year) %>%
  summarise(across(everything(), ~ paste(unique(.), collapse = ",")), .groups = 'drop')

# Identify and resolve duplicates in the offense table
fpO_snap_table <- fpO_snap_table %>%
  group_by(Player, Pos, Year) %>%
  summarise(across(everything(), ~ paste(unique(.), collapse = ",")), .groups = 'drop')

# Pivot the defense table to a wider format
fpD_snap_table_wide <- fpD_snap_table %>%
  pivot_wider(names_from = Year, values_from = -c(Year, Player, Pos), names_prefix = "Year_")

# Pivot the offense table to a wider format
fpO_snap_table_wide <- fpO_snap_table %>%
  pivot_wider(names_from = Year, values_from = -c(Year, Player, Pos), names_prefix = "Year_")

# Combine the wide tables for defense and offense
fp_snap_table_wide <- bind_rows(fpD_snap_table_wide, fpO_snap_table_wide)

```

Adjustments
```{r}
# Convert the TTL_Year_ columns to numeric
fp_snap_table_wide <- fp_snap_table_wide %>%
  mutate(across(starts_with("TTL_Year_"),  ~ 
                  as.numeric(replace(., !is.na(.) & !grepl("^[0-9]+$", .), 0))))

# Create a new column that sums the values in TTL_Year_2016 and the following years
fp_snap_table_wide <- fp_snap_table_wide %>%
  mutate(Total_Career_Snaps = rowSums(select(., starts_with("TTL_Year_")), na.rm = TRUE))

# Rearrange the columns to place the new column as the third column
fp_snap_table_wide <- fp_snap_table_wide %>%
  select(1:2, Total_Career_Snaps, everything())


```


load in combine data. Gonna have to write different code per computer
```{r}
#Alaina
# combine22 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics/2022_combine.csv")
# combine21 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics/2021_combine.csv")
# combine20 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics/2020_combine.csv")
# combine19 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics//2019_combine.csv")
# combine18 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics/2018_combine.csv")
# combine17 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics/2017_combine.csv")
# combine16 <- read.csv("/Users/alainabrady/Desktop/Predictive Analytics/2016_combine.csv")

# #Collin
 # combine22 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2022_combine.csv")
 # combine21 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2021_combine.csv")
 # combine20 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2020_combine.csv")
 # combine19 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2019_combine.csv")
 # combine18 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2018_combine.csv")
 # combine17 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2017_combine.csv")
 # combine16 <- read.csv("C:/Users/cstra/Downloads/NFL_Combine_Data/2016_combine.csv") 
  
#Max
#combine22 <- read.csv()#filepath
#combine21 <- read.csv()#filepath
#combine20 <- read.csv()#filepath
#combine19 <- read.csv()#filepath
#combine18 <- read.csv()#filepath
#combine17 <- read.csv()#filepath
#combine16 <- read.csv()#filepath
  
#Stef
combine22 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2022_combine.csv")#file path
combine21 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2021_combine.csv")#filepath
combine20 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2020_combine.csv")#filepath
combine19 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2019_combine.csv")#filepath
combine18 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2018_combine.csv")#filepath
combine17 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2017_combine.csv")#filepath
combine16 <- read.csv("C:/Users/stefa/OneDrive/Documents/Predictive Analytics/2016_combine.csv")#filepath

all_combine_data <- bind_rows(combine22, combine21, combine20, combine19, combine18, combine17, combine16)

all_combine_data$Player <- gsub("\\.", "", all_combine_data$Player)

fp_snap_table_wide$Player <- gsub("\\.", "", fp_snap_table_wide$Player)

all_combine_data$Player <- toupper(all_combine_data$Player) 

fp_snap_table_wide$Player <- toupper(fp_snap_table_wide$Player)

all_combine_data$Player <- gsub("III", "", all_combine_data$Player)

fp_snap_table_wide$Player <- gsub("III", "", fp_snap_table_wide$Player)


all_combine_data$Player <- gsub("IV", "", all_combine_data$Player)

fp_snap_table_wide$Player <- gsub("IV", "", fp_snap_table_wide$Player)


all_combine_data$Player <- gsub("II", "", all_combine_data$Player)

fp_snap_table_wide$Player <- gsub("II", "", fp_snap_table_wide$Player)

all_combine_data$Player <- gsub("SR", "", all_combine_data$Player)

fp_snap_table_wide$Player <- gsub("SR", "", fp_snap_table_wide$Player)

all_combine_data$Player <- gsub("JR", "", all_combine_data$Player)

fp_snap_table_wide$Player <- gsub("JR", "", fp_snap_table_wide$Player)

all_combine_data$Player <- trimws(all_combine_data$Player)

fp_snap_table_wide$Player <- trimws(fp_snap_table_wide$Player)

```

Inner join combine and snap in to one via player
```{r}
dataset <- all_combine_data %>%
  left_join(fp_snap_table_wide, by = "Player")

#problem on lines 1232/1233 - sure happens elsewhere - duplicate players
#will create new columns in each data set that are "Player & University"
#innerjoin on P&U rather than Player

dataset_unique <- dataset %>%
  filter(!Player %in% Player[duplicated(Player)])


dataset_unique$Total_Career_Snaps[is.na(dataset_unique$Total_Career_Snaps)] <- 0

```
problem on lines 1232/1233 - sure happens elsewhere - duplicate players
first thought was to create a new column of player x position and inner join on that
problem is the combine positions are more detailed and include positions not in the snap table
could dumb down positions in combine data and do that
could also just remove all duplicates

Other cleaning to do:
remove offensive linemen/special teams
could probably get rid of a bunch - dont really need all the weekly 
Others...?
Feel free to throw them down here and we can check them off


Actual whatever the fuck we are doing
```{r}
summary(dataset)

## removing offensive linemen/special teams/positions that dont match between columns
dataset_unique <- dataset_unique[!dataset_unique$Pos.x %in% c("LT", "LG", "C", "RG", "RT","OT", "OG", "K", "LS", "P"), ]
```

Filtering out columns after total career snaps
```{r}
cut_data <- dataset_unique %>%
  select(c(, 1:13))

cut_data <- cut_data %>%
  select(-Pos.y)
```


Grouping positions
```{r}
unique(cut_data$Pos.x)
```

```{r}
DBs <- cut_data %>%
  filter(Pos.x %in% c("S", "CB", "DB"))

LB <- cut_data %>%
  filter(Pos.x %in% c("LB", "OLB", "ILB"))

Dline <- cut_data %>%
  filter(Pos.x %in% c("EDGE", "DT", "DE", "DL"))

TE <- cut_data %>%
  filter(Pos.x %in% c("TE"))

RB <- cut_data %>%
  filter(Pos.x %in% c("RB"))

WR <- cut_data %>%
  filter(Pos.x %in% c("WR"))
``` 



Visualizations
```{r}
ggplot(dataset_unique, aes(x = Ht, y = Wt, color = Pos.x)) +
  geom_point() +
  labs(title = "Height vs Weight by Position", x = "Height (inches)", y = "Weight (lbs)")

ggplot(dataset_unique, aes(x = X40yd)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black") +
  labs(title = "Distribution of 40-yard Dash Times", x = "40-yard Dash Time (seconds)", y = "Count")

ggplot(dataset_unique, aes(x = Pos.x, y = Vertical, fill = Pos.x)) +
  geom_boxplot() +
  labs(title = "Vertical Jump by Position", x = "Position", y = "Vertical Jump (inches)")

ggplot(dataset_unique, aes(x = Pos.x, y = Bench, fill = Pos.x)) +
  geom_boxplot() +
  labs(title = "Bench Press Reps by Position", x = "Position", y = "Bench Press Reps")

ggplot(dataset_unique, aes(x = Pos.x, y = Broad.Jump, fill = Pos.x)) +
  geom_boxplot() +
  labs(title = "Broad Jump by Position", x = "Position", y = "Broad Jump (inches)")

ggplot(dataset_unique, aes(x = X3Cone)) +
  geom_histogram(binwidth = 0.1, fill = "green", color = "black") +
  labs(title = "Distribution of 3-Cone Drill Times", x = "3-Cone Drill Time (seconds)", y = "Count")

ggplot(dataset_unique, aes(x = Shuttle)) +
  geom_histogram(binwidth = 0.05, fill = "purple", color = "black") +
  labs(title = "Distribution of Shuttle Run Times", x = "Shuttle Run Time (seconds)", y = "Count")

ggplot(dataset_unique, aes(x = Pos.x, y = Total_Career_Snaps, fill = Pos.x)) +
  geom_boxplot() +
  labs(title = "Total Career Snaps by Position", x = "Position", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Ht, y = X40yd, color = Pos.x)) +
  geom_point() +
  labs(title = "Height vs 40-yard Dash Time", x = "Height (inches)", y = "40-yard Dash Time (seconds)")

ggplot(dataset_unique, aes(x = Wt, y = Bench, color = Pos.x)) +
  geom_point() +
  labs(title = "Weight vs Bench Press Reps", x = "Weight (lbs)", y = "Bench Press Reps")

```

More
```{r}
ggplot(dataset_unique, aes(x = X40yd, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs 40-yard Dash Time", x = "40-yard Dash Time (seconds)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Vertical, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Vertical Jump", x = "Vertical Jump (inches)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Bench, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Bench Press Reps", x = "Bench Press Reps", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Broad.Jump, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Broad Jump", x = "Broad Jump (inches)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = X3Cone, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs 3-Cone Drill Time", x = "3-Cone Drill Time (seconds)", y = "Total Career Snaps")

```
more!
```{r}
ggplot(dataset_unique, aes(x = Shuttle, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Shuttle Run Time by Position", x = "Shuttle Run Time (seconds)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Ht, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Height by Position", x = "Height (inches)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Wt, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Weight by Position", x = "Weight (lbs)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = X40yd, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs 40-yard Dash Time by Position", x = "40-yard Dash Time (seconds)", y = "Total Career Snaps")

ggplot(dataset_unique, aes(x = Vertical, y = Total_Career_Snaps, color = Pos.x)) +
  geom_point() +
  labs(title = "Total Career Snaps vs Vertical Jump by Position", x = "Vertical Jump (inches)", y = "Total Career Snaps")

```



Random Forest Model


Converting height to inches
```{r}
library(randomForest)

DBs$Ht <- sapply(DBs$Ht, function(x) {
  parts <- strsplit(x, "-")[[1]]
  return(as.numeric(parts[1]) * 12 + as.numeric(parts[2]))
})
```


Making a binary variable as the target

```{r}
DBs$Snap_Count <- ifelse(DBs$Total_Career_Snaps > 50, 1, 0)
```

Finding means and SDs

```{r}
means_sds_DBs <- DBs %>%
  summarise(
    mean_X40yd = mean(X40yd, na.rm = TRUE),
    sd_X40yd = sd(X40yd, na.rm = TRUE),
    mean_Vertical = mean(Vertical, na.rm = TRUE),
    sd_Vertical = sd(Vertical, na.rm = TRUE),
    mean_Bench = mean(Bench, na.rm = TRUE),
    sd_Bench = sd(Bench, na.rm = TRUE),
    mean_Broad = mean(Broad.Jump, na.rm = TRUE),
    sd_Broad = sd(Broad.Jump, na.rm = TRUE),
    mean_X3Cone = mean(X3Cone, na.rm = TRUE),
    sd_X3Cone = sd(X3Cone, na.rm = TRUE),
    mean_Shuttle = mean(Shuttle, na.rm = TRUE),
    sd_Shuttle = sd(Shuttle, na.rm = TRUE)
  )
```

Input the SD's into NAs

```{r}
 DBs <- DBs %>%
  mutate(
    X40yd = ifelse(is.na(X40yd), means_sds_DBs$mean_X40yd + means_sds_DBs$sd_X40yd, X40yd),
    Vertical = ifelse(is.na(Vertical), means_sds_DBs$mean_Vertical - means_sds_DBs$sd_Vertical, Vertical),
    Bench = ifelse(is.na(Bench), means_sds_DBs$mean_Bench - means_sds_DBs$sd_Bench, Bench),
    Broad.Jump = ifelse(is.na(Broad.Jump), means_sds_DBs$mean_Broad - means_sds_DBs$sd_Broad, Broad.Jump),
    X3Cone = ifelse(is.na(X3Cone), means_sds_DBs$mean_X3Cone + means_sds_DBs$sd_X3Cone, X3Cone),
    Shuttle = ifelse(is.na(Shuttle), means_sds_DBs$mean_Shuttle + means_sds_DBs$sd_Shuttle, Shuttle)
  )

```

Remove other NAs

```{r}
DBs <- DBs%>% 
  filter(!is.na(Snap_Count))
```


```{r}

DBs$Pos <- as.factor(DBs$Pos)

DBs <- na.omit(DBs)

DBs$Snap_Count <- as.factor(DBs$Snap_Count)
```



```{r}
set.seed(123532)  
train_indices_DBs <- sample(1:nrow(DBs), 0.8 * nrow(DBs))
train_data_DBs <- DBs[train_indices_DBs, ]
test_data_DBs <- DBs[-train_indices_DBs, ]
```


```{r}
rf_model_DBs <- randomForest(Snap_Count ~ . -Player -School -Total_Career_Snaps, data = train_data_DBs, ntree = 100)
```
```{r}
library(caret)

predictions_DBs <- predict(rf_model_DBs, test_data_DBs)
table_Dbs <- table(predictions_DBs, test_data_DBs$Snap_Count)
confusionMatrix(table_Dbs, positive = "1")
```

LBs

```{r}
LB$Ht <- sapply(LB$Ht, function(x) {
  parts <- strsplit(x, "-")[[1]]
  return(as.numeric(parts[1]) * 12 + as.numeric(parts[2]))
})
```

```{r}
LB$Snap_Count <- ifelse(LB$Total_Career_Snaps > 50, 1, 0)
```


```{r}
means_sds_LB <- LB %>%
  summarise(
    mean_X40yd = mean(X40yd, na.rm = TRUE),
    sd_X40yd = sd(X40yd, na.rm = TRUE),
    mean_Vertical = mean(Vertical, na.rm = TRUE),
    sd_Vertical = sd(Vertical, na.rm = TRUE),
    mean_Bench = mean(Bench, na.rm = TRUE),
    sd_Bench = sd(Bench, na.rm = TRUE),
    mean_Broad = mean(Broad.Jump, na.rm = TRUE),
    sd_Broad = sd(Broad.Jump, na.rm = TRUE),
    mean_X3Cone = mean(X3Cone, na.rm = TRUE),
    sd_X3Cone = sd(X3Cone, na.rm = TRUE),
    mean_Shuttle = mean(Shuttle, na.rm = TRUE),
    sd_Shuttle = sd(Shuttle, na.rm = TRUE)
  )
```

```{r}
LB <- LB %>%
  mutate(
    X40yd = ifelse(is.na(X40yd), means_sds_DBs$mean_X40yd + means_sds_DBs$sd_X40yd, X40yd),
    Vertical = ifelse(is.na(Vertical), means_sds_DBs$mean_Vertical - means_sds_DBs$sd_Vertical, Vertical),
    Bench = ifelse(is.na(Bench), means_sds_DBs$mean_Bench - means_sds_DBs$sd_Bench, Bench),
    Broad.Jump = ifelse(is.na(Broad.Jump), means_sds_DBs$mean_Broad - means_sds_DBs$sd_Broad, Broad.Jump),
    X3Cone = ifelse(is.na(X3Cone), means_sds_DBs$mean_X3Cone + means_sds_DBs$sd_X3Cone, X3Cone),
    Shuttle = ifelse(is.na(Shuttle), means_sds_DBs$mean_Shuttle + means_sds_DBs$sd_Shuttle, Shuttle)
  )

LB <- LB%>% 
  filter(!is.na(Snap_Count))
```

```{r}
LB$Pos <- as.factor(LB$Pos)

LB <- na.omit(LB)

LB$Snap_Count <- as.factor(LB$Snap_Count)
```

```{r}
set.seed(123532)  
train_indices_LB <- sample(1:nrow(LB), 0.8 * nrow(LB))
train_data_LB <- LB[train_indices_LB, ]
test_data_LB <- LB[-train_indices_LB, ]
```

```{r}
rf_model_LB <- randomForest(Snap_Count ~ . -Player -School -Total_Career_Snaps, data = train_data_LB, ntree = 100)
```
```{r}
library(caret)

predictions_LB <- predict(rf_model_LB, test_data_LB)
table_LB <- table(predictions_LB, test_data_LB$Snap_Count)
confusionMatrix(table_LB, positive = "1")
```
DL

```{r}
Dline$Ht <- sapply(Dline$Ht, function(x) {
  parts <- strsplit(x, "-")[[1]]
  return(as.numeric(parts[1]) * 12 + as.numeric(parts[2]))
})
```

```{r}
Dline$Snap_Count <- ifelse(Dline$Total_Career_Snaps > 50, 1, 0)
```


```{r}
means_sds_Dline <- Dline %>%
  summarise(
    mean_X40yd = mean(X40yd, na.rm = TRUE),
    sd_X40yd = sd(X40yd, na.rm = TRUE),
    mean_Vertical = mean(Vertical, na.rm = TRUE),
    sd_Vertical = sd(Vertical, na.rm = TRUE),
    mean_Bench = mean(Bench, na.rm = TRUE),
    sd_Bench = sd(Bench, na.rm = TRUE),
    mean_Broad = mean(Broad.Jump, na.rm = TRUE),
    sd_Broad = sd(Broad.Jump, na.rm = TRUE),
    mean_X3Cone = mean(X3Cone, na.rm = TRUE),
    sd_X3Cone = sd(X3Cone, na.rm = TRUE),
    mean_Shuttle = mean(Shuttle, na.rm = TRUE),
    sd_Shuttle = sd(Shuttle, na.rm = TRUE)
  )
```

```{r}
Dline <- Dline %>%
  mutate(
    X40yd = ifelse(is.na(X40yd), means_sds_DBs$mean_X40yd + means_sds_DBs$sd_X40yd, X40yd),
    Vertical = ifelse(is.na(Vertical), means_sds_DBs$mean_Vertical - means_sds_DBs$sd_Vertical, Vertical),
    Bench = ifelse(is.na(Bench), means_sds_DBs$mean_Bench - means_sds_DBs$sd_Bench, Bench),
    Broad.Jump = ifelse(is.na(Broad.Jump), means_sds_DBs$mean_Broad - means_sds_DBs$sd_Broad, Broad.Jump),
    X3Cone = ifelse(is.na(X3Cone), means_sds_DBs$mean_X3Cone + means_sds_DBs$sd_X3Cone, X3Cone),
    Shuttle = ifelse(is.na(Shuttle), means_sds_DBs$mean_Shuttle + means_sds_DBs$sd_Shuttle, Shuttle)
  )

Dline <- Dline%>% 
  filter(!is.na(Snap_Count))
```

```{r}
Dline$Pos <- as.factor(Dline$Pos)

Dline <- na.omit(Dline)

Dline$Snap_Count <- as.factor(Dline$Snap_Count)
```

```{r}
set.seed(123532)  
train_indices_Dline <- sample(1:nrow(Dline), 0.8 * nrow(Dline))
train_data_Dline <- Dline[train_indices_Dline, ]
test_data_Dline <- Dline[-train_indices_Dline, ]
```

```{r}
rf_model_Dline <- randomForest(Snap_Count ~ . -Player -School -Total_Career_Snaps, data = train_data_Dline, ntree = 100)
```
```{r}
library(caret)

predictions_Dline <- predict(rf_model_Dline, test_data_Dline)
table_Dline <- table(predictions_Dline, test_data_Dline$Snap_Count)
confusionMatrix(table_Dline, positive = "1")
```


RB

```{r}
RB$Ht <- sapply(RB$Ht, function(x) {
  parts <- strsplit(x, "-")[[1]]
  return(as.numeric(parts[1]) * 12 + as.numeric(parts[2]))
})
```

```{r}
RB$Snap_Count <- ifelse(RB$Total_Career_Snaps > 50, 1, 0)
```


```{r}
means_sds_RB <- RB %>%
  summarise(
    mean_X40yd = mean(X40yd, na.rm = TRUE),
    sd_X40yd = sd(X40yd, na.rm = TRUE),
    mean_Vertical = mean(Vertical, na.rm = TRUE),
    sd_Vertical = sd(Vertical, na.rm = TRUE),
    mean_Bench = mean(Bench, na.rm = TRUE),
    sd_Bench = sd(Bench, na.rm = TRUE),
    mean_Broad = mean(Broad.Jump, na.rm = TRUE),
    sd_Broad = sd(Broad.Jump, na.rm = TRUE),
    mean_X3Cone = mean(X3Cone, na.rm = TRUE),
    sd_X3Cone = sd(X3Cone, na.rm = TRUE),
    mean_Shuttle = mean(Shuttle, na.rm = TRUE),
    sd_Shuttle = sd(Shuttle, na.rm = TRUE)
  )
```

```{r}
RB <- RB %>%
  mutate(
    X40yd = ifelse(is.na(X40yd), means_sds_DBs$mean_X40yd + means_sds_DBs$sd_X40yd, X40yd),
    Vertical = ifelse(is.na(Vertical), means_sds_DBs$mean_Vertical - means_sds_DBs$sd_Vertical, Vertical),
    Bench = ifelse(is.na(Bench), means_sds_DBs$mean_Bench - means_sds_DBs$sd_Bench, Bench),
    Broad.Jump = ifelse(is.na(Broad.Jump), means_sds_DBs$mean_Broad - means_sds_DBs$sd_Broad, Broad.Jump),
    X3Cone = ifelse(is.na(X3Cone), means_sds_DBs$mean_X3Cone + means_sds_DBs$sd_X3Cone, X3Cone),
    Shuttle = ifelse(is.na(Shuttle), means_sds_DBs$mean_Shuttle + means_sds_DBs$sd_Shuttle, Shuttle)
  )

RB <- RB%>% 
  filter(!is.na(Snap_Count))
```

```{r}
RB$Pos <- as.factor(RB$Pos)

RB <- na.omit(RB)

RB$Snap_Count <- as.factor(RB$Snap_Count)
```

```{r}
set.seed(123532)  
train_indices_RB <- sample(1:nrow(RB), 0.8 * nrow(RB))
train_data_RB <- RB[train_indices_RB, ]
test_data_RB <- RB[-train_indices_RB, ]
```

```{r}
rf_model_RB <- randomForest(Snap_Count ~ . -Player -School -Total_Career_Snaps, data = train_data_RB, ntree = 100)
```
```{r}
library(caret)

predictions_RB <- predict(rf_model_RB, test_data_RB)
table_RB <- table(predictions_RB, test_data_RB$Snap_Count)
confusionMatrix(table_RB, positive = "1")
```




WR

```{r}
WR$Ht <- sapply(WR$Ht, function(x) {
  parts <- strsplit(x, "-")[[1]]
  return(as.numeric(parts[1]) * 12 + as.numeric(parts[2]))
})
```

```{r}
WR$Snap_Count <- ifelse(WR$Total_Career_Snaps > 50, 1, 0)
```


```{r}
means_sds_WR <- WR %>%
  summarise(
    mean_X40yd = mean(X40yd, na.rm = TRUE),
    sd_X40yd = sd(X40yd, na.rm = TRUE),
    mean_Vertical = mean(Vertical, na.rm = TRUE),
    sd_Vertical = sd(Vertical, na.rm = TRUE),
    mean_Bench = mean(Bench, na.rm = TRUE),
    sd_Bench = sd(Bench, na.rm = TRUE),
    mean_Broad = mean(Broad.Jump, na.rm = TRUE),
    sd_Broad = sd(Broad.Jump, na.rm = TRUE),
    mean_X3Cone = mean(X3Cone, na.rm = TRUE),
    sd_X3Cone = sd(X3Cone, na.rm = TRUE),
    mean_Shuttle = mean(Shuttle, na.rm = TRUE),
    sd_Shuttle = sd(Shuttle, na.rm = TRUE)
  )
```

```{r}
WR <- WR %>%
  mutate(
    X40yd = ifelse(is.na(X40yd), means_sds_DBs$mean_X40yd + means_sds_DBs$sd_X40yd, X40yd),
    Vertical = ifelse(is.na(Vertical), means_sds_DBs$mean_Vertical - means_sds_DBs$sd_Vertical, Vertical),
    Bench = ifelse(is.na(Bench), means_sds_DBs$mean_Bench - means_sds_DBs$sd_Bench, Bench),
    Broad.Jump = ifelse(is.na(Broad.Jump), means_sds_DBs$mean_Broad - means_sds_DBs$sd_Broad, Broad.Jump),
    X3Cone = ifelse(is.na(X3Cone), means_sds_DBs$mean_X3Cone + means_sds_DBs$sd_X3Cone, X3Cone),
    Shuttle = ifelse(is.na(Shuttle), means_sds_DBs$mean_Shuttle + means_sds_DBs$sd_Shuttle, Shuttle)
  )

WR <- WR%>% 
  filter(!is.na(Snap_Count))
```

```{r}
WR$Pos <- as.factor(WR$Pos)

WR <- na.omit(WR)

WR$Snap_Count <- as.factor(WR$Snap_Count)
```

```{r}
set.seed(123532)  
train_indices_WR <- sample(1:nrow(WR), 0.8 * nrow(WR))
train_data_WR <- WR[train_indices_WR, ]
test_data_WR <- WR[-train_indices_WR, ]
```

```{r}
rf_model_WR <- randomForest(Snap_Count ~ . -Player -School -Total_Career_Snaps, data = train_data_WR, ntree = 100)
```
```{r}
library(caret)

predictions_WR <- predict(rf_model_WR, test_data_WR)
table_WR <- table(predictions_WR, test_data_WR$Snap_Count)
confusionMatrix(table_WR, positive = "1")
```







Linear Models


DBs
```{r}
linear_model_DBs <- lm(Total_Career_Snaps ~ Ht + Wt + X40yd + Vertical + Bench + Broad.Jump + X3Cone + Shuttle, data = train_data_DBs)

summary(linear_model_DBs)
```

```{r}
predictions_DBs_Lin <- predict(linear_model_DBs, newdata = test_data_DBs)


results_DBs <- data.frame(Actual = test_data_DBs$Total_Career_Snaps, Predicted = predictions_DBs_Lin)

library(Metrics)
rmse_value_DBs <- rmse(results_DBs$Actual, results_DBs$Predicted)
print(paste("RMSE:", rmse_value_DBs))
```
```{r}
ggplot(results_DBs, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(title = "Actual vs. Predicted Snap Counts - DBs", x = "Actual Snap Count", y = "Predicted Snap Count") +
  theme_minimal()
```
LB

```{r}
linear_model_LB <- lm(Total_Career_Snaps ~ Ht + Wt + X40yd + Vertical + Bench + Broad.Jump + X3Cone + Shuttle, data = train_data_LB)

summary(linear_model_LB)
```
```{r}
predictions_LB_Lin <- predict(linear_model_LB, newdata = test_data_LB)


results_LB <- data.frame(Actual = test_data_LB$Total_Career_Snaps, Predicted = predictions_LB_Lin)

library(Metrics)
rmse_value_LB <- rmse(results_LB$Actual, results_LB$Predicted)
print(paste("RMSE:", rmse_value_LB))
```
```{r}
ggplot(results_LB, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(title = "Actual vs. Predicted Snap Counts - LBs", x = "Actual Snap Count", y = "Predicted Snap Count") +
  theme_minimal()
```
Dline

```{r}
linear_model_Dline <- lm(Total_Career_Snaps ~ Ht + Wt + X40yd + Vertical + Bench + Broad.Jump + X3Cone + Shuttle, data = train_data_Dline)

summary(linear_model_Dline)
```
```{r}
predictions_Dline_Lin <- predict(linear_model_Dline, newdata = test_data_Dline)


results_Dline <- data.frame(Actual = test_data_Dline$Total_Career_Snaps, Predicted = predictions_Dline_Lin)

library(Metrics)
rmse_value_Dline <- rmse(results_Dline$Actual, results_Dline$Predicted)
print(paste("RMSE:", rmse_value_Dline))
```

```{r}
ggplot(results_Dline, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(title = "Actual vs. Predicted Snap Counts - Dline", x = "Actual Snap Count", y = "Predicted Snap Count") +
  theme_minimal()
```
RB

```{r}
linear_model_RB <- lm(Total_Career_Snaps ~ Ht + Wt + X40yd + Vertical + Bench + Broad.Jump + X3Cone + Shuttle, data = train_data_RB)

summary(linear_model_RB)
```
```{r}
predictions_RB_Lin <- predict(linear_model_RB, newdata = test_data_RB)


results_RB <- data.frame(Actual = test_data_RB$Total_Career_Snaps, Predicted = predictions_RB_Lin)

library(Metrics)
rmse_value_RB <- rmse(results_RB$Actual, results_RB$Predicted)
print(paste("RMSE:", rmse_value_RB))
```

```{r}
ggplot(results_RB, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(title = "Actual vs. Predicted Snap Counts - RBs", x = "Actual Snap Count", y = "Predicted Snap Count") +
  theme_minimal()
```
WR

```{r}
linear_model_WR <- lm(Total_Career_Snaps ~ Ht + Wt + X40yd + Vertical + Bench + Broad.Jump + X3Cone + Shuttle, data = train_data_WR)

summary(linear_model_WR)
```
```{r}
predictions_WR_Lin <- predict(linear_model_WR, newdata = test_data_WR)


results_WR <- data.frame(Actual = test_data_WR$Total_Career_Snaps, Predicted = predictions_WR_Lin)

library(Metrics)
rmse_value_WR <- rmse(results_WR$Actual, results_WR$Predicted)
print(paste("RMSE:", rmse_value_WR))
```
```{r}
ggplot(results_WR, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(title = "Actual vs. Predicted Snap Counts - WRs", x = "Actual Snap Count", y = "Predicted Snap Count") +
  theme_minimal()
```

